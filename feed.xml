<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ashbabu.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ashbabu.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-03-18T15:05:05+00:00</updated><id>https://ashbabu.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">a post with code diff</title><link href="https://ashbabu.github.io/blog/2024/code-diff/" rel="alternate" type="text/html" title="a post with code diff"/><published>2024-01-27T19:22:00+00:00</published><updated>2024-01-27T19:22:00+00:00</updated><id>https://ashbabu.github.io/blog/2024/code-diff</id><content type="html" xml:base="https://ashbabu.github.io/blog/2024/code-diff/"><![CDATA[<p>You can display diff code by using the regular markdown syntax:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff
</span><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")
</span></code></pre></div></div> <p>But this is difficult to read, specially if you have a large diff. You can use <a href="https://diff2html.xyz/">diff2html</a> to display a more readable version of the diff. For this, just use <code class="language-plaintext highlighter-rouge">diff2html</code> instead of <code class="language-plaintext highlighter-rouge">diff</code> for the code block language:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff2html
</span><span class="sb">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
--- a/sample.js
+++ b/sample.js
@@ -1 +1 @@
-console.log("Hello World!")
+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>If we use a longer example, for example <a href="https://github.com/rtfpessoa/diff2html/commit/c2c253d3e3f8b8b267f551e659f72b44ca2ac927">this commit from diff2html</a>, it will generate the following output:</p> <pre><code class="language-diff2html">From 2aaae31cc2a37bfff83430c2c914b140bee59b6a Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sun, 9 Oct 2016 16:41:54 +0100
Subject: [PATCH 1/2] Initial template override support

---
 scripts/hulk.js                    |  4 ++--
 src/diff2html.js                   |  3 +--
 src/file-list-printer.js           | 11 ++++++++---
 src/hoganjs-utils.js               | 29 +++++++++++++++++------------
 src/html-printer.js                |  6 ++++++
 src/line-by-line-printer.js        |  6 +++++-
 src/side-by-side-printer.js        |  6 +++++-
 test/file-list-printer-tests.js    |  2 +-
 test/hogan-cache-tests.js          | 18 +++++++++++++++---
 test/line-by-line-tests.js         |  3 +--
 test/side-by-side-printer-tests.js |  3 +--
 11 files changed, 62 insertions(+), 29 deletions(-)

diff --git a/scripts/hulk.js b/scripts/hulk.js
index 5a793c18..a4b1a4d5 100755
--- a/scripts/hulk.js
+++ b/scripts/hulk.js
@@ -173,11 +173,11 @@ function namespace(name) {
 // write a template foreach file that matches template extension
 templates = extractFiles(options.argv.remain)
   .map(function(file) {
-    var openedFile = fs.readFileSync(file, 'utf-8');
+    var openedFile = fs.readFileSync(file, 'utf-8').trim();
     var name;
     if (!openedFile) return;
     name = namespace(path.basename(file).replace(/\..*$/, ''));
-    openedFile = removeByteOrderMark(openedFile.trim());
+    openedFile = removeByteOrderMark(openedFile);
     openedFile = wrap(file, name, openedFile);
     if (!options.outputdir) return openedFile;
     fs.writeFileSync(path.join(options.outputdir, name + '.js')
diff --git a/src/diff2html.js b/src/diff2html.js
index 21b0119e..64e138f5 100644
--- a/src/diff2html.js
+++ b/src/diff2html.js
@@ -7,7 +7,6 @@

 (function() {
   var diffParser = require('./diff-parser.js').DiffParser;
-  var fileLister = require('./file-list-printer.js').FileListPrinter;
   var htmlPrinter = require('./html-printer.js').HtmlPrinter;

   function Diff2Html() {
@@ -43,7 +42,7 @@

     var fileList = '';
     if (configOrEmpty.showFiles === true) {
-      fileList = fileLister.generateFileList(diffJson, configOrEmpty);
+      fileList = htmlPrinter.generateFileListSummary(diffJson, configOrEmpty);
     }

     var diffOutput = '';
diff --git a/src/file-list-printer.js b/src/file-list-printer.js
index e408d9b2..1e0a2c61 100644
--- a/src/file-list-printer.js
+++ b/src/file-list-printer.js
@@ -8,11 +8,16 @@
 (function() {
   var printerUtils = require('./printer-utils.js').PrinterUtils;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var baseTemplatesPath = 'file-summary';
   var iconsBaseTemplatesPath = 'icon';

-  function FileListPrinter() {
+  function FileListPrinter(config) {
+    this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   FileListPrinter.prototype.generateFileList = function(diffFiles) {
@@ -38,5 +43,5 @@
     });
   };

-  module.exports.FileListPrinter = new FileListPrinter();
+  module.exports.FileListPrinter = FileListPrinter;
 })();
diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 9949e5fa..0dda08d7 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -8,18 +8,19 @@
 (function() {
   var fs = require('fs');
   var path = require('path');
-
   var hogan = require('hogan.js');

   var hoganTemplates = require('./templates/diff2html-templates.js');

-  var templatesPath = path.resolve(__dirname, 'templates');
+  var extraTemplates;

-  function HoganJsUtils() {
+  function HoganJsUtils(configuration) {
+    this.config = configuration || {};
+    extraTemplates = this.config.templates || {};
   }

-  HoganJsUtils.prototype.render = function(namespace, view, params, configuration) {
-    var template = this.template(namespace, view, configuration);
+  HoganJsUtils.prototype.render = function(namespace, view, params) {
+    var template = this.template(namespace, view);
     if (template) {
       return template.render(params);
     }
@@ -27,17 +28,16 @@
     return null;
   };

-  HoganJsUtils.prototype.template = function(namespace, view, configuration) {
-    var config = configuration || {};
+  HoganJsUtils.prototype.template = function(namespace, view) {
     var templateKey = this._templateKey(namespace, view);

-    return this._getTemplate(templateKey, config);
+    return this._getTemplate(templateKey);
   };

-  HoganJsUtils.prototype._getTemplate = function(templateKey, config) {
+  HoganJsUtils.prototype._getTemplate = function(templateKey) {
     var template;

-    if (!config.noCache) {
+    if (!this.config.noCache) {
       template = this._readFromCache(templateKey);
     }

@@ -53,6 +53,7 @@

     try {
       if (fs.readFileSync) {
+        var templatesPath = path.resolve(__dirname, 'templates');
         var templatePath = path.join(templatesPath, templateKey);
         var templateContent = fs.readFileSync(templatePath + '.mustache', 'utf8');
         template = hogan.compile(templateContent);
@@ -66,12 +67,16 @@
   };

   HoganJsUtils.prototype._readFromCache = function(templateKey) {
-    return hoganTemplates[templateKey];
+    return extraTemplates[templateKey] || hoganTemplates[templateKey];
   };

   HoganJsUtils.prototype._templateKey = function(namespace, view) {
     return namespace + '-' + view;
   };

-  module.exports.HoganJsUtils = new HoganJsUtils();
+  HoganJsUtils.prototype.compile = function(templateStr) {
+    return hogan.compile(templateStr);
+  };
+
+  module.exports.HoganJsUtils = HoganJsUtils;
 })();
diff --git a/src/html-printer.js b/src/html-printer.js
index 585d5b66..13f83047 100644
--- a/src/html-printer.js
+++ b/src/html-printer.js
@@ -8,6 +8,7 @@
 (function() {
   var LineByLinePrinter = require('./line-by-line-printer.js').LineByLinePrinter;
   var SideBySidePrinter = require('./side-by-side-printer.js').SideBySidePrinter;
+  var FileListPrinter = require('./file-list-printer.js').FileListPrinter;

   function HtmlPrinter() {
   }
@@ -22,5 +23,10 @@
     return sideBySidePrinter.generateSideBySideJsonHtml(diffFiles);
   };

+  HtmlPrinter.prototype.generateFileListSummary = function(diffJson, config) {
+    var fileListPrinter = new FileListPrinter(config);
+    return fileListPrinter.generateFileList(diffJson);
+  };
+
   module.exports.HtmlPrinter = new HtmlPrinter();
 })();
diff --git a/src/line-by-line-printer.js b/src/line-by-line-printer.js
index b07eb53c..d230bedd 100644
--- a/src/line-by-line-printer.js
+++ b/src/line-by-line-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'line-by-line';
   var iconsBaseTemplatesPath = 'icon';
@@ -19,6 +20,9 @@

   function LineByLinePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   LineByLinePrinter.prototype.makeFileDiffHtml = function(file, diffs) {
diff --git a/src/side-by-side-printer.js b/src/side-by-side-printer.js
index bbf1dc8d..5e3033b3 100644
--- a/src/side-by-side-printer.js
+++ b/src/side-by-side-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'side-by-side';
   var iconsBaseTemplatesPath = 'icon';
@@ -26,6 +27,9 @@

   function SideBySidePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   SideBySidePrinter.prototype.makeDiffHtml = function(file, diffs) {
diff --git a/test/file-list-printer-tests.js b/test/file-list-printer-tests.js
index a502a46f..60ea3208 100644
--- a/test/file-list-printer-tests.js
+++ b/test/file-list-printer-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var fileListPrinter = require('../src/file-list-printer.js').FileListPrinter;
+var fileListPrinter = new (require('../src/file-list-printer.js').FileListPrinter)();

 describe('FileListPrinter', function() {
   describe('generateFileList', function() {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 190bf6f8..3bb754ac 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var HoganJsUtils = require('../src/hoganjs-utils.js').HoganJsUtils;
+var HoganJsUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)();
 var diffParser = require('../src/diff-parser.js').DiffParser;

 describe('HoganJsUtils', function() {
@@ -21,16 +21,28 @@ describe('HoganJsUtils', function() {
       });
       assert.equal(emptyDiffHtml, result);
     });
+
     it('should render view without cache', function() {
       var result = HoganJsUtils.render('generic', 'empty-diff', {
         contentClass: 'd2h-code-line',
         diffParser: diffParser
       }, {noCache: true});
-      assert.equal(emptyDiffHtml + '\n', result);
+      assert.equal(emptyDiffHtml, result);
     });
+
     it('should return null if template is missing', function() {
-      var result = HoganJsUtils.render('generic', 'missing-template', {}, {noCache: true});
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)({noCache: true});
+      var result = hoganUtils.render('generic', 'missing-template', {});
       assert.equal(null, result);
     });
+
+    it('should allow templates to be overridden', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+
+      var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
diff --git a/test/line-by-line-tests.js b/test/line-by-line-tests.js
index 1cd92073..8869b3df 100644
--- a/test/line-by-line-tests.js
+++ b/test/line-by-line-tests.js
@@ -14,7 +14,7 @@ describe('LineByLinePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expected, fileHtml);
     });
@@ -422,7 +422,6 @@ describe('LineByLinePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                &lt;/tbody&gt;\n' +
         '            &lt;/table&gt;\n' +
         '        &lt;/div&gt;\n' +
diff --git a/test/side-by-side-printer-tests.js b/test/side-by-side-printer-tests.js
index 76625f8e..771daaa5 100644
--- a/test/side-by-side-printer-tests.js
+++ b/test/side-by-side-printer-tests.js
@@ -14,7 +14,7 @@ describe('SideBySidePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expectedRight, fileHtml.right);
       assert.equal(expectedLeft, fileHtml.left);
@@ -324,7 +324,6 @@ describe('SideBySidePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                    &lt;/tbody&gt;\n' +
         '                &lt;/table&gt;\n' +
         '            &lt;/div&gt;\n' +

From f3cadb96677d0eb82fc2752dc3ffbf35ca9b5bdb Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sat, 15 Oct 2016 13:21:22 +0100
Subject: [PATCH 2/2] Allow uncompiled templates

---
 README.md                 |  3 +++
 src/hoganjs-utils.js      |  7 +++++++
 test/hogan-cache-tests.js | 24 +++++++++++++++++++++++-
 3 files changed, 33 insertions(+), 1 deletion(-)

diff --git a/README.md b/README.md
index 132c8a28..46909f25 100644
--- a/README.md
+++ b/README.md
@@ -98,6 +98,9 @@ The HTML output accepts a Javascript object with configuration. Possible options
   - `synchronisedScroll`: scroll both panes in side-by-side mode: `true` or `false`, default is `false`
   - `matchWordsThreshold`: similarity threshold for word matching, default is 0.25
   - `matchingMaxComparisons`: perform at most this much comparisons for line matching a block of changes, default is `2500`
+  - `templates`: object with previously compiled templates to replace parts of the html
+  - `rawTemplates`: object with raw not compiled templates to replace parts of the html
+  &gt; For more information regarding the possible templates look into [src/templates](https://github.com/rtfpessoa/diff2html/tree/master/src/templates)

 ## Diff2HtmlUI Helper

diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 0dda08d7..b2e9c275 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -17,6 +17,13 @@
   function HoganJsUtils(configuration) {
     this.config = configuration || {};
     extraTemplates = this.config.templates || {};
+
+    var rawTemplates = this.config.rawTemplates || {};
+    for (var templateName in rawTemplates) {
+      if (rawTemplates.hasOwnProperty(templateName)) {
+        if (!extraTemplates[templateName]) extraTemplates[templateName] = this.compile(rawTemplates[templateName]);
+      }
+    }
   }

   HoganJsUtils.prototype.render = function(namespace, view, params) {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 3bb754ac..a34839c0 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -36,7 +36,7 @@ describe('HoganJsUtils', function() {
       assert.equal(null, result);
     });

-    it('should allow templates to be overridden', function() {
+    it('should allow templates to be overridden with compiled templates', function() {
       var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');

       var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
@@ -44,5 +44,27 @@ describe('HoganJsUtils', function() {
       var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
       assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
     });
+
+    it('should allow templates to be overridden with uncompiled templates', function() {
+      var emptyDiffTemplate = '&lt;p&gt;&lt;/p&gt;';
+
+      var config = {rawTemplates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
+
+    it('should allow templates to be overridden giving priority to compiled templates', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+      var emptyDiffTemplateUncompiled = '&lt;p&gt;Not used!&lt;/p&gt;';
+
+      var config = {
+        templates: {'generic-empty-diff': emptyDiffTemplate},
+        rawTemplates: {'generic-empty-diff': emptyDiffTemplateUncompiled}
+      };
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is how you can display code diffs]]></summary></entry><entry><title type="html">a post with advanced image components</title><link href="https://ashbabu.github.io/blog/2024/advanced-images/" rel="alternate" type="text/html" title="a post with advanced image components"/><published>2024-01-27T11:46:00+00:00</published><updated>2024-01-27T11:46:00+00:00</updated><id>https://ashbabu.github.io/blog/2024/advanced-images</id><content type="html" xml:base="https://ashbabu.github.io/blog/2024/advanced-images/"><![CDATA[<p>This is an example post with advanced image components.</p> <h2 id="image-slider">Image Slider</h2> <p>This is a simple image slider. It uses the <a href="https://swiperjs.com/">Swiper</a> library. Check the <a href="https://swiperjs.com/demos">examples page</a> for more information of what you can achieve with it.</p> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true"> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9-480.webp 480w,/assets/img/9-800.webp 800w,/assets/img/9-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/9.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/7-480.webp 480w,/assets/img/7-800.webp 800w,/assets/img/7-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8-480.webp 480w,/assets/img/8-800.webp 800w,/assets/img/8-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/8.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/10-480.webp 480w,/assets/img/10-800.webp 800w,/assets/img/10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/12-480.webp 480w,/assets/img/12-800.webp 800w,/assets/img/12-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/12.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> </swiper-container> <h2 id="image-comparison-slider">Image Comparison Slider</h2> <p>This is a simple image comparison slider. It uses the <a href="https://img-comparison-slider.sneas.io/">img-comparison-slider</a> library. Check the <a href="https://img-comparison-slider.sneas.io/examples.html">examples page</a> for more information of what you can achieve with it.</p> <img-comparison-slider> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/prof_pic.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic_color-480.webp 480w,/assets/img/prof_pic_color-800.webp 800w,/assets/img/prof_pic_color-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/prof_pic_color.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what advanced image components could look like]]></summary></entry><entry><title type="html">a post with vega lite</title><link href="https://ashbabu.github.io/blog/2024/vega-lite/" rel="alternate" type="text/html" title="a post with vega lite"/><published>2024-01-27T00:20:00+00:00</published><updated>2024-01-27T00:20:00+00:00</updated><id>https://ashbabu.github.io/blog/2024/vega-lite</id><content type="html" xml:base="https://ashbabu.github.io/blog/2024/vega-lite/"><![CDATA[<p>This is an example post with some <a href="https://vega.github.io/vega-lite/">vega lite</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">vega_lite
</span><span class="sb">{
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "description": "A dot plot showing each movie in the database, and the difference from the average movie rating. The display is sorted by year to visualize everything in sequential order. The graph is for all Movies before 2019.",
  "data": {
    "url": "https://raw.githubusercontent.com/vega/vega/main/docs/data/movies.json"
  },
  "transform": [
    {"filter": "datum['IMDB Rating'] != null"},
    {"filter": {"timeUnit": "year", "field": "Release Date", "range": [null, 2019]}},
    {
      "joinaggregate": [{
        "op": "mean",
        "field": "IMDB Rating",
        "as": "AverageRating"
      }]
    },
    {
      "calculate": "datum['IMDB Rating'] - datum.AverageRating",
      "as": "RatingDelta"
    }
  ],
  "mark": "point",
  "encoding": {
    "x": {
      "field": "Release Date",
      "type": "temporal"
    },
    "y": {
      "field": "RatingDelta",
      "type": "quantitative",
      "title": "Rating Delta"
    },
    "color": {
      "field": "RatingDelta",
      "type": "quantitative",
      "scale": {"domainMid": 0},
      "title": "Rating Delta"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-vega_lite">{
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "description": "A dot plot showing each movie in the database, and the difference from the average movie rating. The display is sorted by year to visualize everything in sequential order. The graph is for all Movies before 2019.",
  "data": {
    "url": "https://raw.githubusercontent.com/vega/vega/main/docs/data/movies.json"
  },
  "transform": [
    {"filter": "datum['IMDB Rating'] != null"},
    {"filter": {"timeUnit": "year", "field": "Release Date", "range": [null, 2019]}},
    {
      "joinaggregate": [{
        "op": "mean",
        "field": "IMDB Rating",
        "as": "AverageRating"
      }]
    },
    {
      "calculate": "datum['IMDB Rating'] - datum.AverageRating",
      "as": "RatingDelta"
    }
  ],
  "mark": "point",
  "encoding": {
    "x": {
      "field": "Release Date",
      "type": "temporal"
    },
    "y": {
      "field": "RatingDelta",
      "type": "quantitative",
      "title": "Rating Delta"
    },
    "color": {
      "field": "RatingDelta",
      "type": "quantitative",
      "scale": {"domainMid": 0},
      "title": "Rating Delta"
    }
  }
}
</code></pre> <p>This plot supports both light and dark themes.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included vega lite code could look like]]></summary></entry><entry><title type="html">a post with geojson</title><link href="https://ashbabu.github.io/blog/2024/geojson-map/" rel="alternate" type="text/html" title="a post with geojson"/><published>2024-01-26T17:57:00+00:00</published><updated>2024-01-26T17:57:00+00:00</updated><id>https://ashbabu.github.io/blog/2024/geojson-map</id><content type="html" xml:base="https://ashbabu.github.io/blog/2024/geojson-map/"><![CDATA[<p>This is an example post with some <a href="https://geojson.org/">geojson</a> code. The support is provided thanks to <a href="https://leafletjs.com/">Leaflet</a>. To create your own visualization, go to <a href="https://geojson.io/">geojson.io</a>.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">geojson
</span><span class="sb">{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {},
      "geometry": {
        "coordinates": [
          [
            [
              -60.11363029935569,
              -2.904625022183211
            ],
            [
              -60.11363029935569,
              -3.162613728707967
            ],
            [
              -59.820894493858034,
              -3.162613728707967
            ],
            [
              -59.820894493858034,
              -2.904625022183211
            ],
            [
              -60.11363029935569,
              -2.904625022183211
            ]
          ]
        ],
        "type": "Polygon"
      }
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-geojson">{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {},
      "geometry": {
        "coordinates": [
          [
            [
              -60.11363029935569,
              -2.904625022183211
            ],
            [
              -60.11363029935569,
              -3.162613728707967
            ],
            [
              -59.820894493858034,
              -3.162613728707967
            ],
            [
              -59.820894493858034,
              -2.904625022183211
            ],
            [
              -60.11363029935569,
              -2.904625022183211
            ]
          ]
        ],
        "type": "Polygon"
      }
    }
  ]
}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><category term="maps"/><summary type="html"><![CDATA[this is what included geojson code could look like]]></summary></entry><entry><title type="html">a post with echarts</title><link href="https://ashbabu.github.io/blog/2024/echarts/" rel="alternate" type="text/html" title="a post with echarts"/><published>2024-01-26T16:03:00+00:00</published><updated>2024-01-26T16:03:00+00:00</updated><id>https://ashbabu.github.io/blog/2024/echarts</id><content type="html" xml:base="https://ashbabu.github.io/blog/2024/echarts/"><![CDATA[<p>This is an example post with some <a href="https://echarts.apache.org/">echarts</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">echarts
</span><span class="sb">{
  "title": {
    "text": "ECharts Getting Started Example"
  },
  "responsive": true,
  "tooltip": {},
  "legend": {
    "top": "30px",
    "data": ["sales"]
  },
  "xAxis": {
    "data": ["Shirts", "Cardigans", "Chiffons", "Pants", "Heels", "Socks"]
  },
  "yAxis": {},
  "series": [
    {
      "name": "sales",
      "type": "bar",
      "data": [5, 20, 36, 10, 10, 20]
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-echarts">{
  "title": {
    "text": "ECharts Getting Started Example"
  },
  "responsive": true,
  "tooltip": {},
  "legend": {
    "top": "30px",
    "data": ["sales"]
  },
  "xAxis": {
    "data": ["Shirts", "Cardigans", "Chiffons", "Pants", "Heels", "Socks"]
  },
  "yAxis": {},
  "series": [
    {
      "name": "sales",
      "type": "bar",
      "data": [5, 20, 36, 10, 10, 20]
    }
  ]
}
</code></pre> <p>Note that this library offer support for both light and dark themes. You can switch between them using the theme switcher in the top right corner of the page.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included echarts code could look like]]></summary></entry><entry><title type="html">a post with chart.js</title><link href="https://ashbabu.github.io/blog/2024/chartjs/" rel="alternate" type="text/html" title="a post with chart.js"/><published>2024-01-26T01:04:00+00:00</published><updated>2024-01-26T01:04:00+00:00</updated><id>https://ashbabu.github.io/blog/2024/chartjs</id><content type="html" xml:base="https://ashbabu.github.io/blog/2024/chartjs/"><![CDATA[<p>This is an example post with some <a href="https://www.chartjs.org/">chart.js</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">chartjs
</span><span class="sb">{
  "type": "line",
  "data": {
    "labels": [
      "January",
      "February",
      "March",
      "April",
      "May",
      "June",
      "July"
    ],
    "datasets": [
      {
        "label": "# of bugs",
        "fill": false,
        "lineTension": 0.1,
        "backgroundColor": "rgba(75,192,192,0.4)",
        "borderColor": "rgba(75,192,192,1)",
        "borderCapStyle": "butt",
        "borderDash": [],
        "borderDashOffset": 0,
        "borderJoinStyle": "miter",
        "pointBorderColor": "rgba(75,192,192,1)",
        "pointBackgroundColor": "#fff",
        "pointBorderWidth": 1,
        "pointHoverRadius": 5,
        "pointHoverBackgroundColor": "rgba(75,192,192,1)",
        "pointHoverBorderColor": "rgba(220,220,220,1)",
        "pointHoverBorderWidth": 2,
        "pointRadius": 1,
        "pointHitRadius": 10,
        "data": [
          65,
          59,
          80,
          81,
          56,
          55,
          40
        ],
        "spanGaps": false
      }
    ]
  },
  "options": {}
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>This is how it looks like:</p> <pre><code class="language-chartjs">{
  "type": "line",
  "data": {
    "labels": [
      "January",
      "February",
      "March",
      "April",
      "May",
      "June",
      "July"
    ],
    "datasets": [
      {
        "label": "# of bugs",
        "fill": false,
        "lineTension": 0.1,
        "backgroundColor": "rgba(75,192,192,0.4)",
        "borderColor": "rgba(75,192,192,1)",
        "borderCapStyle": "butt",
        "borderDash": [],
        "borderDashOffset": 0,
        "borderJoinStyle": "miter",
        "pointBorderColor": "rgba(75,192,192,1)",
        "pointBackgroundColor": "#fff",
        "pointBorderWidth": 1,
        "pointHoverRadius": 5,
        "pointHoverBackgroundColor": "rgba(75,192,192,1)",
        "pointHoverBorderColor": "rgba(220,220,220,1)",
        "pointHoverBorderWidth": 2,
        "pointRadius": 1,
        "pointHitRadius": 10,
        "data": [
          65,
          59,
          80,
          81,
          56,
          55,
          40
        ],
        "spanGaps": false
      }
    ]
  },
  "options": {}
}
</code></pre> <p>Also another example chart.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">chartjs
</span><span class="sb">{
  "type": "doughnut",
  "data": {
    "labels": [
      "Red",
      "Blue",
      "Yellow"
    ],
    "datasets": [
      {
        "data": [
          300,
          50,
          100
        ],
        "backgroundColor": [
          "#FF6384",
          "#36A2EB",
          "#FFCE56"
        ],
        "hoverBackgroundColor": [
          "#FF6384",
          "#36A2EB",
          "#FFCE56"
        ]
      }
    ]
  },
  "options": {}
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-chartjs">{
  "type": "doughnut",
  "data": {
    "labels": [
      "Red",
      "Blue",
      "Yellow"
    ],
    "datasets": [
      {
        "data": [
          300,
          50,
          100
        ],
        "backgroundColor": [
          "#FF6384",
          "#36A2EB",
          "#FFCE56"
        ],
        "hoverBackgroundColor": [
          "#FF6384",
          "#36A2EB",
          "#FFCE56"
        ]
      }
    ]
  },
  "options": {}
}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included chart.js code could look like]]></summary></entry><entry><title type="html">a post with TikZJax</title><link href="https://ashbabu.github.io/blog/2023/tikzjax/" rel="alternate" type="text/html" title="a post with TikZJax"/><published>2023-12-12T22:25:00+00:00</published><updated>2023-12-12T22:25:00+00:00</updated><id>https://ashbabu.github.io/blog/2023/tikzjax</id><content type="html" xml:base="https://ashbabu.github.io/blog/2023/tikzjax/"><![CDATA[<p>This is an example post with TikZ code. TikZJax converts script tags (containing TikZ code) into SVGs.</p> <script type="text/tikz">
\begin{tikzpicture}
    \draw[red,fill=black!60!red] (0,0) circle [radius=1.5];
    \draw[green,fill=black!60!green] (0,0) circle [x radius=1.5cm, y radius=10mm];
    \draw[blue,fill=black!60!blue] (0,0) circle [x radius=1cm, y radius=5mm, rotate=30];
\end{tikzpicture}
</script>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included TikZ code could look like]]></summary></entry><entry><title type="html">Part 03 : Deploying a trained Semantic segmentation model</title><link href="https://ashbabu.github.io/blog/2023/Deploying-trained-Semantic-segmentation-model/" rel="alternate" type="text/html" title="Part 03 : Deploying a trained Semantic segmentation model"/><published>2023-08-09T01:22:00+00:00</published><updated>2023-08-09T01:22:00+00:00</updated><id>https://ashbabu.github.io/blog/2023/Deploying-trained-Semantic-segmentation-model</id><content type="html" xml:base="https://ashbabu.github.io/blog/2023/Deploying-trained-Semantic-segmentation-model/"><![CDATA[<p>This article builds upon the previous two post, viz., <a href="/blog/2023/Semantic-segmentation/">training</a>, <a href="/blog/2023/Inference-on-trained-Semantic-segmentation-model/">inference</a> and shows how a live video stream from intel realsense camera could be used to do inference. This only gives a basic idea and there are other methods like <code class="language-plaintext highlighter-rouge">tensorrt</code>, <code class="language-plaintext highlighter-rouge">torchscript</code>, <code class="language-plaintext highlighter-rouge">onnx</code> etc for faster inference.</p> <p>The implementation uses ROS but it can be done otherwise as well using the realsense SDK</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import rospy
from sensor_msgs.msg import Image
from cv_bridge import CvBridge
import cv2
import torch
import numpy as np
import utils_fn as util
from lightningModel import OurModel

class Deploy<span class="o">(</span>object<span class="o">)</span>:
    def __init__<span class="o">(</span>self, <span class="nv">modelPath</span><span class="o">=</span><span class="s2">"chk_pts/trained_cityscapes_final.pth"</span>, <span class="nv">lightning</span><span class="o">=</span>False<span class="o">)</span>:
        <span class="c"># Params</span>
        self.image <span class="o">=</span> None
        self.lightning <span class="o">=</span> lightning
        self.br <span class="o">=</span> CvBridge<span class="o">()</span>
        <span class="c"># Node cycle rate (in Hz).</span>
        self.loop_rate <span class="o">=</span> rospy.Rate<span class="o">(</span>1<span class="o">)</span>
        self.modelPath <span class="o">=</span> modelPath
        self.loadModel<span class="o">(</span>self.modelPath, <span class="nv">lightning</span><span class="o">=</span>self.lightning<span class="o">)</span>
        self.imgPath <span class="o">=</span> <span class="s2">"../datasets/cityscapes/leftImg8bit/img.png"</span>
        <span class="c"># Subscribers</span>
        rospy.Subscriber<span class="o">(</span><span class="s2">"/camera/color/image_raw"</span>, Image, self.callback<span class="o">)</span>

    def callback<span class="o">(</span>self, msg<span class="o">)</span>:
        <span class="k">if </span>msg is not None:
            rospy.loginfo<span class="o">(</span><span class="s1">'Image received...'</span><span class="o">)</span>
            self.image <span class="o">=</span> self.br.imgmsg_to_cv2<span class="o">(</span>msg<span class="o">)</span>

    def loadModel<span class="o">(</span>self, <span class="nv">modelPath</span><span class="o">=</span>None, <span class="nv">lightning</span><span class="o">=</span>False<span class="o">)</span>:
        <span class="k">if </span>lightning:
            self.model <span class="o">=</span> OurModel<span class="o">(</span><span class="nv">n_classes</span><span class="o">=</span>20<span class="o">)</span>
            self.model.load_state_dict<span class="o">(</span>torch.load<span class="o">(</span><span class="s1">'chk_pts/model.pth'</span><span class="o">))</span>
        <span class="k">elif </span>modelPath is not None:
            self.model <span class="o">=</span> torch.load<span class="o">(</span>modelPath<span class="o">)[</span><span class="s2">"model"</span><span class="o">]</span>
        <span class="k">else</span>:
            self.model <span class="o">=</span> torch.load<span class="o">(</span>self.modelPath<span class="o">)[</span><span class="s2">"model"</span><span class="o">]</span>

        self.model.to<span class="o">(</span>util.device<span class="o">)</span>
        self.model.eval<span class="o">()</span>

    def getPrediction<span class="o">(</span>self, img_tensor<span class="o">)</span>:
        with torch.no_grad<span class="o">()</span>:
            prediction <span class="o">=</span> self.model<span class="o">(</span>img_tensor.to<span class="o">(</span>util.device<span class="o">))</span>.squeeze<span class="o">(</span>0<span class="o">)</span>
        <span class="k">return </span>prediction.detach<span class="o">()</span>.cpu<span class="o">()</span>

    def postProcess<span class="o">(</span>self, prediction<span class="o">)</span>:
        t <span class="o">=</span> torch.argmax<span class="o">(</span>prediction, 0<span class="o">)</span>
        decoded_output <span class="o">=</span> util.decode_segmap<span class="o">(</span>t<span class="o">)</span>
        <span class="k">return </span>cv2.cvtColor<span class="o">(</span>decoded_output.astype<span class="o">(</span>np.float32<span class="o">)</span>, cv2.COLOR_RGB2BGR<span class="o">)</span>

    def showImage<span class="o">(</span>self, img<span class="o">)</span>:
        cv2.namedWindow<span class="o">(</span><span class="s2">"Image window"</span>, cv2.WINDOW_NORMAL<span class="o">)</span>
        cv2.imshow<span class="o">(</span><span class="s2">"Image window"</span>, img<span class="o">)</span>
        cv2.waitKey<span class="o">(</span>3<span class="o">)</span>

    def start<span class="o">(</span>self<span class="o">)</span>:
        <span class="k">while </span>not rospy.is_shutdown<span class="o">()</span>:
            <span class="k">if </span>self.image is not None:
                imgCV2 <span class="o">=</span> cv2.cvtColor<span class="o">(</span>self.image, cv2.COLOR_BGR2RGB<span class="o">)</span>
                img_tensor <span class="o">=</span> util.transform<span class="o">(</span><span class="nv">image</span><span class="o">=</span>imgCV2<span class="o">)[</span><span class="s2">"image"</span><span class="o">]</span>.unsqueeze<span class="o">(</span>0<span class="o">)</span>
                invimg <span class="o">=</span> util.inv_normalize<span class="o">(</span>img_tensor<span class="o">)</span>.squeeze<span class="o">(</span>0<span class="o">)</span>
                predicted <span class="o">=</span> self.getPrediction<span class="o">(</span>img_tensor<span class="o">)</span>
                processed_image <span class="o">=</span> self.postProcess<span class="o">(</span>predicted<span class="o">)</span>
                numpy_horizontal <span class="o">=</span> np.hstack<span class="o">((</span>np.moveaxis<span class="o">(</span>invimg.numpy<span class="o">()</span>, 0, 2<span class="o">)</span>, processed_image<span class="o">))</span>
                self.showImage<span class="o">(</span>numpy_horizontal<span class="o">)</span>
            self.loop_rate.sleep<span class="o">()</span>


<span class="k">if </span>__name__ <span class="o">==</span> <span class="s1">'__main__'</span>:
    rospy.init_node<span class="o">(</span><span class="s2">"deploy"</span>, <span class="nv">anonymous</span><span class="o">=</span>True<span class="o">)</span>
    modelPath <span class="o">=</span> <span class="s2">"chk_pts/hrnet_latest.pth"</span>
    my_node <span class="o">=</span> Deploy<span class="o">(</span><span class="nv">modelPath</span><span class="o">=</span>modelPath, <span class="nv">lightning</span><span class="o">=</span>True<span class="o">)</span>
    my_node.start<span class="o">()</span>
print<span class="o">(</span><span class="s2">"done"</span><span class="o">)</span>
</code></pre></div></div> <h3 id="explanation">Explanation</h3> <p>The <code class="language-plaintext highlighter-rouge">cv_bridge</code> package is used to convert <code class="language-plaintext highlighter-rouge">sensor_msgs/Image</code> to <code class="language-plaintext highlighter-rouge">opencv</code> format. This converted image is sent to the model for performing inference.</p>]]></content><author><name></name></author><category term="Computer-Vision"/><summary type="html"><![CDATA[This article builds upon the previous two post, viz., training, inference and shows how a live video stream from intel realsense camera could be used to do inference. This only gives a basic idea and there are other methods like tensorrt, torchscript, onnx etc for faster inference.]]></summary></entry><entry><title type="html">Part 02 : Inference on trained Semantic segmentation model</title><link href="https://ashbabu.github.io/blog/2023/Inference-on-trained-Semantic-segmentation-model/" rel="alternate" type="text/html" title="Part 02 : Inference on trained Semantic segmentation model"/><published>2023-07-29T01:22:00+00:00</published><updated>2023-07-29T01:22:00+00:00</updated><id>https://ashbabu.github.io/blog/2023/Inference-on-trained-Semantic-segmentation-model</id><content type="html" xml:base="https://ashbabu.github.io/blog/2023/Inference-on-trained-Semantic-segmentation-model/"><![CDATA[<p>This briefly gives an overview of how a neural network could be used perform semantic segmentation inference. The <a href="/blog/2023/Semantic-segmentation/">previous post</a> showed how a model could be trained and this builds upon that.</p> <p>The training of the model is carried out by using models from <code class="language-plaintext highlighter-rouge">segmentation_models_pytorch</code> as this is an easy to use library for training several models. The training script is as follows</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import cv2
import torch
import numpy as np
from PIL import Image
import utils_fn as util
import matplotlib.pyplot as plt
use_opencv <span class="o">=</span> False

imgPath <span class="o">=</span> <span class="s2">"path/to/the/image.png"</span>

<span class="k">if </span>use_opencv:
    imgCV2 <span class="o">=</span> cv2.imread<span class="o">(</span>imgPath<span class="o">)</span>
    imgCV2 <span class="o">=</span> cv2.cvtColor<span class="o">(</span>imgCV2, cv2.COLOR_BGR2RGB<span class="o">)</span>
    img_tensor <span class="o">=</span> util.transform<span class="o">(</span><span class="nv">image</span><span class="o">=</span>imgCV2<span class="o">)[</span><span class="s2">"image"</span><span class="o">]</span>.unsqueeze<span class="o">(</span>0<span class="o">)</span>
<span class="k">else</span>:
    imgPIL <span class="o">=</span> Image.open<span class="o">(</span>imgPath<span class="o">)</span>.convert<span class="o">(</span><span class="s2">"RGB"</span><span class="o">)</span>
    img_tensor <span class="o">=</span> util.transform<span class="o">(</span><span class="nv">image</span><span class="o">=</span>np.array<span class="o">(</span>imgPIL<span class="o">))[</span><span class="s2">"image"</span><span class="o">]</span>.unsqueeze<span class="o">(</span>0<span class="o">)</span>

model <span class="o">=</span> torch.load<span class="o">(</span><span class="s2">"chk_pts/trained_cityscapes_final.pth"</span><span class="o">)[</span><span class="s2">"model"</span><span class="o">]</span>
model.to<span class="o">(</span>util.device<span class="o">)</span>
model.eval<span class="o">()</span>
<span class="c"># Get prediction:</span>
with torch.no_grad<span class="o">()</span>:
    prediction <span class="o">=</span> model<span class="o">(</span>img_tensor.to<span class="o">(</span>util.device<span class="o">))</span>.squeeze<span class="o">(</span>0<span class="o">)</span>

invimg <span class="o">=</span> util.inv_normalize<span class="o">(</span>img_tensor<span class="o">)</span>.squeeze<span class="o">(</span>0<span class="o">)</span>
output <span class="o">=</span> prediction.detach<span class="o">()</span>.cpu<span class="o">()</span>
t <span class="o">=</span> torch.argmax<span class="o">(</span>output, 0<span class="o">)</span>
decoded_output <span class="o">=</span> util.decode_segmap<span class="o">(</span>t<span class="o">)</span>

<span class="k">if </span>use_opencv:
    tt <span class="o">=</span> cv2.cvtColor<span class="o">(</span>decoded_output.astype<span class="o">(</span>np.float32<span class="o">)</span>, cv2.COLOR_RGB2BGR<span class="o">)</span>
    numpy_horizontal <span class="o">=</span> np.hstack<span class="o">((</span>np.moveaxis<span class="o">(</span>invimg.numpy<span class="o">()</span>, 0, 2<span class="o">)</span>, tt<span class="o">))</span>
    cv2.namedWindow<span class="o">(</span><span class="s2">"image"</span>, cv2.WINDOW_NORMAL<span class="o">)</span>
    cv2.imshow<span class="o">(</span><span class="s1">'image'</span>, numpy_horizontal<span class="o">)</span>
    cv2.waitKey<span class="o">(</span>0<span class="o">)</span>
    cv2.destroyAllWindows<span class="o">()</span>
<span class="k">else</span>:
    fig, ax <span class="o">=</span> plt.subplots<span class="o">(</span><span class="nv">ncols</span><span class="o">=</span>2, <span class="nv">figsize</span><span class="o">=(</span>16, 50<span class="o">)</span>, <span class="nv">facecolor</span><span class="o">=</span><span class="s1">'white'</span><span class="o">)</span>
    ax[0].imshow<span class="o">(</span>np.moveaxis<span class="o">(</span>invimg.numpy<span class="o">()</span>, 0, 2<span class="o">))</span>
    ax[1].imshow<span class="o">(</span>decoded_output<span class="o">)</span>
    plt.show<span class="o">()</span>
print<span class="o">(</span><span class="s2">"done"</span><span class="o">)</span>
</code></pre></div></div> <h3 id="results">Results</h3> <p><img style="float: left;" title="Camera calibration" src="/assets/img/computer-vision/semantic_seg/semantic_segmentation_biefield.png" alt="Camera Calibration" width="750" height="400"/></p> <p><img style="float: left;" title="Camera calibration" src="/assets/img/computer-vision/semantic_seg/semantic_segmentation_munich.png" width="750" height="400"/></p>]]></content><author><name></name></author><category term="Computer-Vision"/><summary type="html"><![CDATA[This briefly gives an overview of how a neural network could be used perform semantic segmentation inference. The previous post showed how a model could be trained and this builds upon that.]]></summary></entry><entry><title type="html">Part 01 : Training a Semantic segmentation model</title><link href="https://ashbabu.github.io/blog/2023/Semantic-segmentation/" rel="alternate" type="text/html" title="Part 01 : Training a Semantic segmentation model"/><published>2023-07-16T01:22:00+00:00</published><updated>2023-07-16T01:22:00+00:00</updated><id>https://ashbabu.github.io/blog/2023/Semantic-segmentation</id><content type="html" xml:base="https://ashbabu.github.io/blog/2023/Semantic-segmentation/"><![CDATA[<p>This briefly gives an overview of how a neural network could be trainded to perform semantic segmentation. I use the <a href="https://www.cityscapes-dataset.com/login/">Cityscapes dataset</a>. You would require a login id and password to download the dataset. Once you obtain this, download the <code class="language-plaintext highlighter-rouge">gtFine_trainvaltest.zip</code> and the <code class="language-plaintext highlighter-rouge">leftImg8bit_trainvaltest.zip</code>. Setup your virtual environment with</p> <ul> <li><code class="language-plaintext highlighter-rouge">numpy</code>, <code class="language-plaintext highlighter-rouge">Pillow</code>, <code class="language-plaintext highlighter-rouge">albumentations</code>, <code class="language-plaintext highlighter-rouge">typing_extensions</code>, <code class="language-plaintext highlighter-rouge">torchvision==0.15.2</code>, <code class="language-plaintext highlighter-rouge">torch==2.0.1</code>, <code class="language-plaintext highlighter-rouge">segmentation-models-pytorch</code>, <code class="language-plaintext highlighter-rouge">torchmetrics</code>, <code class="language-plaintext highlighter-rouge">opencv-python</code>, <code class="language-plaintext highlighter-rouge">matplotlib</code></li> </ul> <p>I have created a utility function python file which does all the repeated tasks and it is as follows</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch
import numpy as np
from PIL import Image
import albumentations as A
from typing import Any, Tuple
import torchvision.transforms as T
from torchvision.datasets import Cityscapes
from albumentations.pytorch import ToTensorV2


def save_checkpoint<span class="o">(</span>epoch, model, optimizer, <span class="nv">name</span><span class="o">=</span><span class="s2">"chkpt.pth.tar"</span><span class="o">)</span>:
    <span class="s2">"""
    Save model checkpoint.

    :param epoch: epoch number
    :param model: model
    :param optimizer: optimizer
    :param name: name of the saved model
    """</span>
    state <span class="o">=</span> <span class="o">{</span><span class="s1">'epoch'</span>: epoch,
             <span class="s1">'model'</span>: model,
             <span class="s1">'optimizer'</span>: optimizer<span class="o">}</span>
    torch.save<span class="o">(</span>state, name<span class="o">)</span>


def writeToFile<span class="o">(</span>content, <span class="nv">filename</span><span class="o">=</span><span class="s2">"metrics.txt"</span>, <span class="nv">mode</span><span class="o">=</span><span class="s2">"w"</span> <span class="o">)</span>:
    with open<span class="o">(</span>filename, mode<span class="o">)</span> as f:
        f.write<span class="o">(</span>str<span class="o">(</span>content<span class="o">))</span>
    f.close<span class="o">()</span>

device <span class="o">=</span> torch.device<span class="o">(</span><span class="s2">"cuda:0"</span> <span class="k">if </span>torch.cuda.is_available<span class="o">()</span> <span class="k">else</span> <span class="s2">"cpu"</span><span class="o">)</span>

inv_normalize <span class="o">=</span> T.Normalize<span class="o">(</span>
    <span class="nv">mean</span><span class="o">=[</span><span class="nt">-0</span>.485 / 0.229, <span class="nt">-0</span>.456 / 0.224, <span class="nt">-0</span>.406 / 0.225],
    <span class="nv">std</span><span class="o">=[</span>1 / 0.229, 1 / 0.224, 1 / 0.255]
<span class="o">)</span>

ignore_index <span class="o">=</span> 255
void_classes <span class="o">=</span> <span class="o">[</span>0, 1, 2, 3, 4, 5, 6, 9, 10, 14, 15, 16, 18, 29, 30, <span class="nt">-1</span><span class="o">]</span>
valid_classes <span class="o">=</span> <span class="o">[</span>ignore_index, 7, 8, 11, 12, 13, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 31, 32, 33]
class_names <span class="o">=</span> <span class="o">[</span><span class="s1">'unlabelled'</span>, <span class="s1">'road'</span>, <span class="s1">'sidewalk'</span>, <span class="s1">'building'</span>, <span class="s1">'wall'</span>, <span class="s1">'fence'</span>, <span class="s1">'pole'</span>, <span class="s1">'traffic_light'</span>, <span class="se">\</span>
               <span class="s1">'traffic_sign'</span>, <span class="s1">'vegetation'</span>, <span class="s1">'terrain'</span>, <span class="s1">'sky'</span>, <span class="s1">'person'</span>, <span class="s1">'rider'</span>, <span class="s1">'car'</span>, <span class="s1">'truck'</span>, <span class="s1">'bus'</span>, <span class="se">\</span>
               <span class="s1">'train'</span>, <span class="s1">'motorcycle'</span>, <span class="s1">'bicycle'</span><span class="o">]</span>
<span class="c">#why i choose 20 classes</span>
<span class="c">#https://stackoverflow.com/a/64242989</span>

class_map <span class="o">=</span> dict<span class="o">(</span>zip<span class="o">(</span>valid_classes, range<span class="o">(</span>len<span class="o">(</span>valid_classes<span class="o">))))</span>
num_of_classes <span class="o">=</span> len<span class="o">(</span>valid_classes<span class="o">)</span>

colors <span class="o">=</span> <span class="o">[[</span>0,   0,   0],
        <span class="o">[</span>128, 64, 128],
        <span class="o">[</span>244, 35, 232],
        <span class="o">[</span>70, 70, 70],
        <span class="o">[</span>102, 102, 156],
        <span class="o">[</span>190, 153, 153],
        <span class="o">[</span>153, 153, 153],
        <span class="o">[</span>250, 170, 30],
        <span class="o">[</span>220, 220, 0],
        <span class="o">[</span>107, 142, 35],
        <span class="o">[</span>152, 251, 152],
        <span class="o">[</span>0, 130, 180],
        <span class="o">[</span>220, 20, 60],
        <span class="o">[</span>255, 0, 0],
        <span class="o">[</span>0, 0, 142],
        <span class="o">[</span>0, 0, 70],
        <span class="o">[</span>0, 60, 100],
        <span class="o">[</span>0, 80, 100],
        <span class="o">[</span>0, 0, 230],
        <span class="o">[</span>119, 11, 32],
    <span class="o">]</span>

label_colours <span class="o">=</span> dict<span class="o">(</span>zip<span class="o">(</span>range<span class="o">(</span>num_of_classes<span class="o">)</span>, colors<span class="o">))</span>

transform <span class="o">=</span> A.Compose<span class="o">(</span>
<span class="o">[</span>
    <span class="c"># A.Resize(224, 224),</span>
    A.Resize<span class="o">(</span>256, 512<span class="o">)</span>,
    A.HorizontalFlip<span class="o">()</span>,
    A.Normalize<span class="o">(</span><span class="nv">mean</span><span class="o">=(</span>0.485, 0.456, 0.406<span class="o">)</span>, <span class="nv">std</span><span class="o">=(</span>0.229, 0.224, 0.225<span class="o">))</span>,
    ToTensorV2<span class="o">()</span>,
<span class="o">]</span>
<span class="o">)</span>


def encode_segmap<span class="o">(</span>mask<span class="o">)</span>:
    <span class="c">#remove unwanted classes and recitify the labels of wanted classes</span>
    <span class="k">for </span>_voidc <span class="k">in </span>void_classes:
        mask[mask <span class="o">==</span> _voidc] <span class="o">=</span> ignore_index
    <span class="k">for </span>_validc <span class="k">in </span>valid_classes:
        mask[mask <span class="o">==</span> _validc] <span class="o">=</span> class_map[_validc]
    <span class="k">return </span>mask


def decode_segmap<span class="o">(</span>temp<span class="o">)</span>:
    <span class="c">#convert gray scale to color</span>
    a <span class="o">=</span> label_colours.copy<span class="o">()</span>
    temp <span class="o">=</span> temp.numpy<span class="o">()</span>
    r <span class="o">=</span> temp.copy<span class="o">()</span>
    g <span class="o">=</span> temp.copy<span class="o">()</span>
    b <span class="o">=</span> temp.copy<span class="o">()</span>
    <span class="k">for </span>l <span class="k">in </span>range<span class="o">(</span>0, num_of_classes<span class="o">)</span>:
        r[temp <span class="o">==</span> l] <span class="o">=</span> label_colours[l][0]
        g[temp <span class="o">==</span> l] <span class="o">=</span> label_colours[l][1]
        b[temp <span class="o">==</span> l] <span class="o">=</span> label_colours[l][2]

    rr, gg, bb <span class="o">=</span> temp.copy<span class="o">()</span>, temp.copy<span class="o">()</span>, temp.copy<span class="o">()</span>
    <span class="k">for </span>l <span class="k">in </span>range<span class="o">(</span>num_of_classes<span class="o">)</span>:
        <span class="k">for </span>i <span class="k">in </span>range<span class="o">(</span>temp.shape[0]<span class="o">)</span>:
            <span class="k">for </span>j <span class="k">in </span>range<span class="o">(</span>temp.shape[1]<span class="o">)</span>:
                <span class="k">if </span>temp[i, j] <span class="o">==</span> l:
                    rr[i, j] <span class="o">=</span> label_colours[l][0]
                    gg[i, j] <span class="o">=</span> label_colours[l][1]
                    bb[i, j] <span class="o">=</span> label_colours[l][2]

    rgb <span class="o">=</span> np.zeros<span class="o">((</span>temp.shape[0], temp.shape[1], 3<span class="o">))</span>
    rgb[:, :, 0] <span class="o">=</span> r / 255.0
    rgb[:, :, 1] <span class="o">=</span> g / 255.0
    rgb[:, :, 2] <span class="o">=</span> b / 255.0
    <span class="k">return </span>rgb


class MyClass<span class="o">(</span>Cityscapes<span class="o">)</span>:
    def __getitem__<span class="o">(</span>self, index: int<span class="o">)</span> -&gt; Tuple[Any, Any]:
        image <span class="o">=</span> Image.open<span class="o">(</span>self.images[index]<span class="o">)</span>.convert<span class="o">(</span><span class="s1">'RGB'</span><span class="o">)</span>

        targets: Any <span class="o">=</span> <span class="o">[]</span>
        <span class="k">for </span>i, t <span class="k">in </span>enumerate<span class="o">(</span>self.target_type<span class="o">)</span>:
            <span class="k">if </span>t <span class="o">==</span> <span class="s1">'polygon'</span>:
                target <span class="o">=</span> self._load_json<span class="o">(</span>self.targets[index][i]<span class="o">)</span>
            <span class="k">else</span>:
                target <span class="o">=</span> Image.open<span class="o">(</span>self.targets[index][i]<span class="o">)</span>
            targets.append<span class="o">(</span>target<span class="o">)</span>
        target <span class="o">=</span> tuple<span class="o">(</span>targets<span class="o">)</span> <span class="k">if </span>len<span class="o">(</span>targets<span class="o">)</span> <span class="o">&gt;</span> 1 <span class="k">else </span>targets[0]

        <span class="k">if </span>self.transforms is not None:
            transformed <span class="o">=</span> transform<span class="o">(</span><span class="nv">image</span><span class="o">=</span>np.array<span class="o">(</span>image<span class="o">)</span>, <span class="nv">mask</span><span class="o">=</span>np.array<span class="o">(</span>target<span class="o">))</span>
        <span class="k">return </span>transformed[<span class="s1">'image'</span><span class="o">]</span>, transformed[<span class="s1">'mask'</span><span class="o">]</span>
</code></pre></div></div> <p>The training of the model is carried out by using models from <code class="language-plaintext highlighter-rouge">segmentation_models_pytorch</code> as this is an easy to use library for training several models. The training script is as follows</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import torch
import torchmetrics
import utils_fn as utl
import multiprocessing
from torch.utils.data import DataLoader
import segmentation_models_pytorch as smp

transform <span class="o">=</span> utl.transform
numworker <span class="o">=</span> multiprocessing.cpu_count<span class="o">()</span> // 4
batch_size <span class="o">=</span> 32

trainset <span class="o">=</span> utl.MyClass<span class="o">(</span><span class="s1">'../../datasets/cityscapes/'</span>, <span class="nb">split</span><span class="o">=</span><span class="s1">'train'</span>, <span class="nv">mode</span><span class="o">=</span><span class="s1">'fine'</span>, <span class="nv">target_type</span><span class="o">=</span><span class="s1">'semantic'</span>, <span class="nv">transforms</span><span class="o">=</span>utl.transform<span class="o">)</span>
valset <span class="o">=</span> utl.MyClass<span class="o">(</span><span class="s1">'../../datasets/cityscapes/'</span>, <span class="nb">split</span><span class="o">=</span><span class="s1">'val'</span>, <span class="nv">mode</span><span class="o">=</span><span class="s1">'fine'</span>, <span class="nv">target_type</span><span class="o">=</span><span class="s1">'semantic'</span>, <span class="nv">transforms</span><span class="o">=</span>utl.transform<span class="o">)</span>
trainloader <span class="o">=</span> DataLoader<span class="o">(</span>trainset, <span class="nv">batch_size</span><span class="o">=</span>batch_size,  <span class="nv">shuffle</span><span class="o">=</span>True, <span class="nv">num_workers</span><span class="o">=</span>numworker, <span class="nv">pin_memory</span><span class="o">=</span>True<span class="o">)</span>
valloader <span class="o">=</span> DataLoader<span class="o">(</span>valset, <span class="nv">batch_size</span><span class="o">=</span>batch_size,  <span class="nv">shuffle</span><span class="o">=</span>False, <span class="nv">num_workers</span><span class="o">=</span>numworker, <span class="nv">pin_memory</span><span class="o">=</span>True<span class="o">)</span>

<span class="c"># https://github.com/qubvel/segmentation_models.pytorch#models</span>
model <span class="o">=</span> smp.Unet<span class="o">(</span>
        <span class="nv">encoder_name</span><span class="o">=</span><span class="s2">"timm-mobilenetv3_small_minimal_100"</span>, <span class="c"># choose encoder, e.g. mobilenet_v2 or efficientnet-b7</span>
        <span class="nv">encoder_weights</span><span class="o">=</span><span class="s2">"imagenet"</span>,     <span class="c"># use `imagenet` pre-trained weights for encoder initialization</span>
        <span class="nv">in_channels</span><span class="o">=</span>3,                  <span class="c"># model input channels (1 for gray-scale images, 3 for RGB, etc.)</span>
        <span class="nv">classes</span><span class="o">=</span>utl.num_of_classes,
        <span class="o">)</span>

model <span class="o">=</span> model.to<span class="o">(</span>utl.device<span class="o">)</span>


lr <span class="o">=</span> 0.001
momentum <span class="o">=</span> 0.9
weightDecay <span class="o">=</span> 0.005

params <span class="o">=</span> <span class="o">[</span>p <span class="k">for </span>p <span class="k">in </span>model.parameters<span class="o">()</span> <span class="k">if </span>p.requires_grad]
optimizer <span class="o">=</span> torch.optim.AdamW<span class="o">(</span>params, <span class="nv">lr</span><span class="o">=</span>lr<span class="o">)</span>
metrics <span class="o">=</span> torchmetrics.JaccardIndex<span class="o">(</span><span class="nv">num_classes</span><span class="o">=</span>utl.num_of_classes, <span class="nv">task</span><span class="o">=</span><span class="s2">"multiclass"</span><span class="o">)</span>
metrics1 <span class="o">=</span> torchmetrics.classification.Accuracy<span class="o">(</span><span class="nv">num_classes</span><span class="o">=</span>utl.num_of_classes, <span class="nv">task</span><span class="o">=</span><span class="s2">"multiclass"</span><span class="o">)</span>

criterion <span class="o">=</span> smp.losses.DiceLoss<span class="o">(</span><span class="nv">mode</span><span class="o">=</span><span class="s1">'multiclass'</span><span class="o">)</span>

dataloader <span class="o">=</span> <span class="o">{</span><span class="s2">"train"</span>: trainloader, <span class="s2">"val"</span>: valloader<span class="o">}</span>


def train_model<span class="o">(</span>model, dataloader, criterion, optimizer, num_epochs, <span class="nv">load_chkpt</span><span class="o">=</span>False, <span class="nv">path</span><span class="o">=</span>None<span class="o">)</span>:
    <span class="k">for </span>epoch <span class="k">in </span>range<span class="o">(</span>num_epochs<span class="o">)</span>:
        print<span class="o">(</span>f<span class="s2">"Epoch: {epoch}/{num_epochs}"</span><span class="o">)</span>
        train_loss <span class="o">=</span> 0.0
        model.train<span class="o">()</span>
        ii <span class="o">=</span> 0
        <span class="k">for </span>inputs, labels <span class="k">in </span>trainloader:
            <span class="k">if </span>ii % 100 <span class="o">==</span> 0:
                print<span class="o">(</span>ii<span class="o">)</span>
            inputs <span class="o">=</span> inputs.to<span class="o">(</span>utl.device<span class="o">)</span>
            labels <span class="o">=</span> labels.to<span class="o">(</span>utl.device<span class="o">)</span>.long<span class="o">()</span>
            optimizer.zero_grad<span class="o">()</span>
            predictions <span class="o">=</span> model.forward<span class="o">(</span>inputs<span class="o">)</span>
            target <span class="o">=</span> utl.encode_segmap<span class="o">(</span>labels<span class="o">)</span>
            loss <span class="o">=</span> criterion<span class="o">(</span>predictions, target<span class="o">)</span>
            acc <span class="o">=</span> metrics1<span class="o">(</span>predictions, target<span class="o">)</span>
            loss.backward<span class="o">()</span>
            optimizer.step<span class="o">()</span>
            train_loss +<span class="o">=</span> loss.item<span class="o">()</span>
            ii +<span class="o">=</span> 1

        valid_loss <span class="o">=</span> 0.0
        model.eval<span class="o">()</span>  <span class="c"># Optional when not using Model Specific layer</span>
        <span class="k">for </span>inputs, labels <span class="k">in </span>valloader:
            inputs <span class="o">=</span> inputs.to<span class="o">(</span>utl.device<span class="o">)</span>
            labels <span class="o">=</span> labels.to<span class="o">(</span>utl.device<span class="o">)</span>.long<span class="o">()</span>
            predictions <span class="o">=</span> model.forward<span class="o">(</span>inputs<span class="o">)</span>
            target <span class="o">=</span> utl.encode_segmap<span class="o">(</span>labels<span class="o">)</span>
            loss <span class="o">=</span> criterion<span class="o">(</span>predictions, target<span class="o">)</span>
            valid_loss <span class="o">=</span> loss.item<span class="o">()</span> <span class="k">*</span> inputs.size<span class="o">(</span>0<span class="o">)</span>

        print<span class="o">(</span>f<span class="s1">'Epoch {epoch + 1} \t\t Training Loss: {train_loss / len(trainloader)} \t\t Validation Loss: {valid_loss / len(valloader)}'</span><span class="o">)</span>
        <span class="k">if </span>not epoch % 20 and epoch <span class="o">!=</span> num_epochs:  <span class="c"># save model every 20 epoch</span>
            print<span class="o">(</span><span class="s2">"Saving model"</span><span class="o">)</span>
            utl.save_checkpoint<span class="o">(</span><span class="nv">epoch</span><span class="o">=</span>epoch, <span class="nv">model</span><span class="o">=</span>model, <span class="nv">optimizer</span><span class="o">=</span>optimizer,
                                <span class="nv">name</span><span class="o">=</span><span class="s2">"chk_pts/trained_cityscapes_"</span> + model.name + <span class="s2">"_"</span> + str<span class="o">(</span>epoch<span class="o">)</span> + <span class="s2">".pth"</span><span class="o">)</span>
        <span class="k">if </span>epoch <span class="o">==</span> num_epochs - 1:
            utl.save_checkpoint<span class="o">(</span><span class="nv">epoch</span><span class="o">=</span>epoch, <span class="nv">model</span><span class="o">=</span>model, <span class="nv">optimizer</span><span class="o">=</span>optimizer,
                                <span class="nv">name</span><span class="o">=</span><span class="s2">"chk_pts/trained_cityscapes_final_"</span> + model.name + <span class="s2">".pth"</span><span class="o">)</span>
            acc <span class="o">=</span> metrics1.compute<span class="o">()</span>
            content <span class="o">=</span> <span class="o">{</span><span class="s2">"Accuracy"</span>: acc.item<span class="o">()</span>, <span class="s2">"Epochs"</span>: epoch+1, <span class="s2">"ModelName"</span>: model.name, <span class="s2">"Train_loss"</span>: train_loss, <span class="s2">"Valid_loss"</span>: valid_loss<span class="o">}</span>
            utl.writeToFile<span class="o">(</span><span class="nv">content</span><span class="o">=</span>content, <span class="nv">filename</span><span class="o">=</span>model.name + <span class="s2">"_metrics.txt"</span>, <span class="nv">mode</span><span class="o">=</span><span class="s2">"w"</span><span class="o">)</span>

chkpt_path <span class="o">=</span> <span class="s2">"chk_pts/trained_cityscapes.pth"</span>
train_model<span class="o">(</span><span class="nv">model</span><span class="o">=</span>model, <span class="nv">dataloader</span><span class="o">=</span>dataloader, <span class="nv">criterion</span><span class="o">=</span>criterion, <span class="nv">optimizer</span><span class="o">=</span>optimizer, <span class="nv">num_epochs</span><span class="o">=</span>10,
            <span class="nv">load_chkpt</span><span class="o">=</span>False, <span class="nv">path</span><span class="o">=</span>chkpt_path<span class="o">)</span>
print<span class="o">(</span><span class="s2">"done"</span><span class="o">)</span>
</code></pre></div></div> <h3 id="a-few-things-to-note">A few things to note</h3> <ul> <li>Here <code class="language-plaintext highlighter-rouge">../../datasets/cityscapes/</code> is the folder where the <code class="language-plaintext highlighter-rouge">gtFine</code> and <code class="language-plaintext highlighter-rouge">leftImg8bit</code> folders are present. Both these folders are inside the downloaded and extracted <code class="language-plaintext highlighter-rouge">gtFine_trainvaltest.zip</code> and the <code class="language-plaintext highlighter-rouge">leftImg8bit_trainvaltest.zip</code> respectively.</li> <li>Albumentations is much faster than the torchvision.transforms library</li> <li>Play aroud with the model as explained in the <a href="https://github.com/qubvel/segmentation_models.pytorch#models">segmentations_model_pytorch github</a></li> </ul>]]></content><author><name></name></author><category term="Computer-Vision"/><summary type="html"><![CDATA[This briefly gives an overview of how a neural network could be trainded to perform semantic segmentation. I use the Cityscapes dataset. You would require a login id and password to download the dataset. Once you obtain this, download the gtFine_trainvaltest.zip and the leftImg8bit_trainvaltest.zip. Setup your virtual environment with numpy, Pillow, albumentations, typing_extensions, torchvision==0.15.2, torch==2.0.1, segmentation-models-pytorch, torchmetrics, opencv-python, matplotlib]]></summary></entry></feed>