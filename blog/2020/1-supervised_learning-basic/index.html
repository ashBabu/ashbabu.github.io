<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Ashith Shyam Babu, PhD | Part1: Supervised Learning: Basic linear regression</title>
    <meta name="author" content="Ashith Shyam Babu, PhD" />
    <meta name="description" content="Building blocks of supervised learning" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ”¥</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://ashbabu.github.io/blog/2020/1-supervised_learning-basic/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://ashbabu.github.io/"><span class="font-weight-bold">Ashith</span> Shyam  Babu, PhD</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">blog</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/blog/category/robotics/">Robotics</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/blog/category/programming/">Programming</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/blog/category/computer-vision/">Computer Vision</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/blog/category/reinforcement-learning/">Reinforcement Learning</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/blog/category/machine-learning/">Machine Learning</a>
                </div>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/contact/">contact</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Part1: Supervised Learning: Basic linear regression</h1>
    <p class="post-meta">January 14, 2020</p>
    <p class="post-tags">
      <a href="/blog/2020"> <i class="fas fa-calendar fa-sm"></i> 2020 </a>
      Â  Â· Â 
        <a href="/blog/category/Machine-Learning">
          <i class="fas fa-tag fa-sm"></i> Machine-Learning</a> Â 
          

    </p>
  </header>

  <article class="post-content">
    <!-- <div style="text-align: justify"> <a href="https://www.ros.org/"> ROS </a> -->
<p><!-- </div> -->
The evolution of Supervised Learning has been very interesting for me. When I was at school, this used to be called curve fitting and the teachers used to give 2D or max 3D problems (for example predict the future house price given the history) so as to visualize on a graph plot. Then during statistics class in college, the same was called Regression and currently everything is some kind of learning and hence I guess the name Supervised Learning. This post is an introduction which uses simple example to understand the basics</p>

<p>As I mentioned, the goal of a Supervised Learning is to predict the future outcomes given the history. A mathematical model, of the form \(y = f(x)\), is used to make an approximation of the real world data. Here \(y\) is called the true label or outcome/output (eg: house prices) and \(x\) is the input or features (eg: number of bedrooms, area of the house in sqaure units etc. that affect the price of the house). Instead of going the traditional way, here I would like to solve the problem of house prediction explicitly and go deeper in to the math. The following is a basic example to understand the concept and in practice several small techniques might need to get a good prediction.</p>

<p>So, imagine if house pricing was as easy as a house costs 50k + 100k per bedroom, so that a 1 bedroom house costs 150k, a 2 bedroom house costs 250k etc. (Here (50, 100) are the weights or parameters that we will find out). We will be given the data, ie.,</p>

<p><code class="language-plaintext highlighter-rouge">house prices, (y):</code> 150k, 250k, 350k <br>
<code class="language-plaintext highlighter-rouge">Number of bedrooms, (nB):</code> 1, 2, 3<br>
A plot of the house price vs number of bedrooms is shown here for a better understanding. From this, it is clear that the cost of a 4 bedroom house would be 450k and so on.</p>
<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/machine-learning/housePrice_vs_nBedrooms-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/machine-learning/housePrice_vs_nBedrooms-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/machine-learning/housePrice_vs_nBedrooms-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/machine-learning/housePrice_vs_nBedrooms.png" data-zoomable="">

  </picture>

</figure>

<p><br></p>

<h4 id="mathematical-model-1">Mathematical model 1:</h4>
<p>\begin{align}
	y = w_0 + w_1 \times nB 
	\label{line1}
\end{align}
where <code class="language-plaintext highlighter-rouge">w's</code> are weights that need to be found out and <code class="language-plaintext highlighter-rouge">nB</code>â€™s (or <code class="language-plaintext highlighter-rouge">x</code>) are the number of bedrooms. If this can be found out as accurately as possible (by any means), then the Supervised Learning problem can be considered solved. In most general form, eq. \ref{line1} can be represented as</p>

<p>\begin{equation}
	y = bias~ (intercept) + slope * n_B \nonumber
\end{equation}</p>

<figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/machine-learning/slope_intercept-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/machine-learning/slope_intercept-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/machine-learning/slope_intercept-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/machine-learning/slope_intercept.png" data-zoomable="">

  </picture>

</figure>

<p>where <code class="language-plaintext highlighter-rouge">w_0</code> is the bias or intercept and <code class="language-plaintext highlighter-rouge">w_1</code> is called the slope. In matrix form, this can be written as
\begin{align}
	Y &amp;= \begin{bmatrix}
           1 &amp; nB
        \end{bmatrix} \begin{bmatrix}
                              w_0 \nonumber \newline
                              w_1
                        \end{bmatrix} \newline
      &amp;= X^Tw
\end{align}
In this particular case, the matrix equation looks like
\begin{align}
	\begin{bmatrix}
		150 \nonumber \newline
		250 \nonumber \newline
		350
    \end{bmatrix}  = \begin{bmatrix}
       					1 &amp; 1  \nonumber \newline
       					1 &amp; 2  \nonumber \newline
       					1 &amp; 3
    				 \end{bmatrix}
        			 \begin{bmatrix}
                      	w_0 \nonumber \newline
                      	w_1
                     \end{bmatrix} 
\end{align}</p>

<p>Because this is a mathematical model, there would be an error (or residual) and this can be written as
\begin{equation}
	error = w_0 + w_1 \times n_B  - y
\end{equation}
The total error will be the sum of the individual errors which can be written as 
\begin{align}
	e &amp;= \sum_{i=1}^{N} (X^Tw - y_i  )
\end{align}
In the example provided, the error becomes 
\begin{align}
	e &amp;= (w_0 + w_1) -150 + (w_0 + 2w_1) - 250 + (w_0 + 3w_1) -350 \nonumber \newline
	&amp;= (3w_0 + 6w_1) - 750 \nonumber
\end{align}</p>

<p>The aim of the regression analysis is to minimize this error and find out suitable value for the parameter <code class="language-plaintext highlighter-rouge">w's</code>. The most common technique used to solve this is Optimization where the objective function returns a scalar whose value is greater than or equal to zero. Formulating our problem as an optimization, it can be written as minimizing the sum of squared errors</p>

<p>\begin{align}
	\rm{Goal:} ~ argmin~ Z = e^Te = \sum_{i=1}^{N} (X^Tw - y_i)^2
\end{align}
The sum of the square of the errors is also called Loss function, <code class="language-plaintext highlighter-rouge">L</code></p>

<p>\begin{align}
	L = e^Te &amp;= (Xw - Y)^T (Xw - Y) 
	\label{eqn:lossfun}
\end{align}</p>

<p><strong>Note:</strong> The loss function is squared so that the minimum of it is zero. Optimization algorithms (<code class="language-plaintext highlighter-rouge">SLSQP</code>, <code class="language-plaintext highlighter-rouge">BFGS</code>, <code class="language-plaintext highlighter-rouge">fmincon</code> etc.) are designed to search for the parameters (here <code class="language-plaintext highlighter-rouge">w</code>â€™s) that take the value of the function (<code class="language-plaintext highlighter-rouge">Z</code>) to a number as close to zero like \(10^{-04}\). (Achieving perfect zero is impossible except for simple problems).</p>

<p>To find the weights, we need to set the gradient of <code class="language-plaintext highlighter-rouge">L</code> with respect to <code class="language-plaintext highlighter-rouge">w</code> to be zero.</p>

<p>Setting the gradient of eq. \ref{eqn:lossfun} to zero, we get</p>

<p>\begin{align}
	\frac{\partial L}{\partial w} &amp;= \frac{\partial L}{\partial e}  \frac{\partial e}{\partial w} \nonumber \newline
	&amp;= 2eX\nonumber\newline
	&amp;= 2(Xw - Y)^TX = 0 \label{eqn:derivative}	
\end{align}
Taking the transpose of eq. \ref{eqn:derivative}, we get</p>

<p>\begin{align}
	X^T(Xw - Y) = 0 \implies w = (X^TX)^{-1}X^TY
	\label{eqn:weightvector}
\end{align}
where the quantity \((X^TX)^{-1}X^T\) is called the <code class="language-plaintext highlighter-rouge">left pseudo-inverse</code></p>

<p>A little bit of code in <code class="language-plaintext highlighter-rouge">Python</code> to solve the same</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>       <span class="c1"># library for mathematics (linear algebra)
</span>
<span class="n">nB</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mf">2.0</span><span class="p">,</span> <span class="mf">3.0</span><span class="p">,</span> <span class="p">])</span>  <span class="c1"># Num bedrooms
</span><span class="n">Y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mf">150.0</span><span class="p">,</span> <span class="mf">250.0</span><span class="p">,</span> <span class="mf">350.0</span><span class="p">])</span>  <span class="c1"># Cost
</span>

<span class="n">s</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ones</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">nB</span><span class="p">)).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">hstack</span><span class="p">((</span><span class="n">s</span><span class="p">,</span> <span class="n">nB</span><span class="p">.</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)))</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">transpose</span><span class="p">()</span> <span class="o">@</span> <span class="n">X</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">transpose</span><span class="p">()</span> <span class="o">@</span> <span class="n">Y</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">solve</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>  <span class="c1"># To find parameters
</span><span class="nf">print</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>

<span class="c1">######
</span><span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]</span>
</code></pre></div></div>
<p>Isnâ€™t this what we started with :-D !!!</p>

  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2023 Ashith Shyam Babu, PhD. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
  </body>
</html>

